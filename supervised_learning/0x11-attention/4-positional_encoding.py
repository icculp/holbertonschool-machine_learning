#!/usr/bin/env python3
"""
    Attention
"""
import numpy as np


def positional_encoding(max_seq_len, dm):
    """ calculates the positional encoding for a transformer
        max_seq_len is an integer representing the maximum sequence length
        dm is the model depth
        Returns: a numpy.ndarray of shape (max_seq_len, dm) containing the positional encoding vectors
    """
    pe = np.ndarray()
    return pe
